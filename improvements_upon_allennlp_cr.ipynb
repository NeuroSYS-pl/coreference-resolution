{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('anaphors': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d03d5abba74e86978e68a6ade085aee69b84e82c031d22c409c19824e6ca40c1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from spacy.tokens import Doc, Span\n",
    "from utils import load_models, print_clusters, print_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor, nlp = load_models()"
   ]
  },
  {
   "source": [
    "## The problem\n",
    "AllenNLP coreference resolution models seems to find better clusters - numerous clusters that are usually more accurate than the ones found by Huggingface NeuralCoref model. However, the biggest problem lies in the next step - the step of replacing found mentions with the most meaningfull spans from each clusters (that we call the \"heads\"). We've found a couple of easy-to-fix problems which seem to lead to errors most often. Our ideas can be summed up as:\n",
    "- not resolving coreferences in the clusters that doesn't contain any noun phrases (usually it comes down to the clusters composed only of pronouns),\n",
    "- chosing the head of the cluster which is a noun phrase (isn't a pronoun),\n",
    "- resolving only the inner span in the case of nested coreferent mentions.\n",
    "\n",
    "We show all of our improvements by example - for more details please refer to our [third and last blog post](). If you're interested in problems themselves our [second blog post](https://neurosys.com/article/most-popular-frameworks-for-coreference-resolution/) contains all the definitions and theory."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Original AllenNLP impelemntation of the `replace_corefs` method\n",
    "\n",
    "We extract the main \"logic\" into the separate function that will be used in our every method as we leave the core of AllenNLP's logic untouched. So as for now, we will compare our solutions to the `original_replace_corefs` method implemented in AllenNLP `coref.py` (we've just copied it here explicitly in order to compare with the improved method we propose)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_logic_part(document: Doc, coref: List[int], resolved: List[str], mention_span: Span):\n",
    "    final_token = document[coref[1]]\n",
    "    if final_token.tag_ in [\"PRP$\", \"POS\"]:\n",
    "        resolved[coref[0]] = mention_span.text + \"'s\" + final_token.whitespace_\n",
    "    else:\n",
    "        resolved[coref[0]] = mention_span.text + final_token.whitespace_\n",
    "    for i in range(coref[0] + 1, coref[1] + 1):\n",
    "        resolved[i] = \"\"\n",
    "    return resolved\n",
    "\n",
    "\n",
    "def original_replace_corefs(document: Doc, clusters: List[List[List[int]]]) -> str:\n",
    "    resolved = list(tok.text_with_ws for tok in document)\n",
    "\n",
    "    for cluster in clusters:\n",
    "        mention_start, mention_end = cluster[0][0], cluster[0][1] + 1\n",
    "        mention_span = document[mention_start:mention_end]\n",
    "\n",
    "        for coref in cluster[1:]:\n",
    "            core_logic_part(document, coref, resolved, mention_span)\n",
    "\n",
    "    return \"\".join(resolved)"
   ]
  },
  {
   "source": [
    "## Improvements\n",
    "### Redundant clusters - lack of a meaningfull mention that could become the head\n",
    "We completely ignore (we don't resove them at all) the clusters that doesn't contain any noun phrase."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span_noun_indices(doc: Doc, cluster: List[List[int]]) -> List[int]:\n",
    "    spans = [doc[span[0]:span[1]+1] for span in cluster]\n",
    "    spans_pos = [[token.pos_ for token in span] for span in spans]\n",
    "    span_noun_indices = [i for i, span_pos in enumerate(spans_pos)\n",
    "        if any(pos in span_pos for pos in ['NOUN', 'PROPN'])]\n",
    "    return span_noun_indices\n",
    "\n",
    "def improved_replace_corefs(document, clusters):\n",
    "    resolved = list(tok.text_with_ws for tok in document)\n",
    "\n",
    "    for cluster in clusters:\n",
    "        noun_indices = get_span_noun_indices(document, cluster)\n",
    "\n",
    "        if noun_indices:  # if there is at least one noun phrase...\n",
    "            mention_start, mention_end = cluster[0][0], cluster[0][1] + 1\n",
    "            mention_span = document[mention_start:mention_end]\n",
    "\n",
    "            for coref in cluster[1:]:\n",
    "                core_logic_part(document, coref, resolved, mention_span)\n",
    "\n",
    "    return \"\".join(resolved)"
   ]
  },
  {
   "source": [
    "**Example**  \n",
    "We want to take our code and create a game. Let's remind ourselves how to do that.  \n",
    "\n",
    "**Original coreference resolution clusters** (by AllenNLP)Â   \n",
    "We --> We; our; 's; ourselves  \n",
    "create --> create; that"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"We want to take our code and create a game. Let's remind ourselves how to do that.\"\n",
    "clusters = predictor.predict(text)['clusters']\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "~~~ AllenNLP original replace_corefs ~~~\nWe want to take We's code and create a game. LetWe remind We how to do create.\n\n~~~ Our improved replace_corefs ~~~\nWe want to take our code and create a game. Let's remind ourselves how to do that.\n"
     ]
    }
   ],
   "source": [
    "print_comparison(original_replace_corefs(doc, clusters), improved_replace_corefs(doc, clusters))"
   ]
  },
  {
   "source": [
    "### Cataphora problem - choosing the wrong cluster *head*\n",
    "We redefine the span that becomes a cluster head. Instead of choosing the first mention in the cluster, we pick the one that is the first **noun phrase in the cluster** - we define it as the first span that contains a noun."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_head(doc: Doc, cluster: List[List[int]], noun_indices: List[int]):\n",
    "    head_idx = noun_indices[0]\n",
    "    head_start, head_end = cluster[head_idx]\n",
    "    head_span = doc[head_start:head_end+1]\n",
    "    return head_span, [head_start, head_end]\n",
    "\n",
    "\n",
    "def improved_replace_corefs(document, clusters):\n",
    "    resolved = list(tok.text_with_ws for tok in document)\n",
    "\n",
    "    for cluster in clusters:\n",
    "        noun_indices = get_span_noun_indices(document, cluster)\n",
    "\n",
    "        if noun_indices:\n",
    "            mention_span, mention = get_cluster_head(document, cluster, noun_indices)\n",
    "\n",
    "            for coref in cluster:\n",
    "                if coref != mention:  # we don't replace the head itself\n",
    "                    core_logic_part(document, coref, resolved, mention_span)\n",
    "\n",
    "    return \"\".join(resolved)"
   ]
  },
  {
   "source": [
    "**Example**   \n",
    "\"He is a great actor!\", he said about John Travolta.\n",
    "\n",
    "**Original coreference resolution clusters** (by AllenNLP)  \n",
    "He --> He; John Travolta"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '\"He is a great actor!\", he said about John Travolta.'\n",
    "clusters = predictor.predict(text)['clusters']\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "~~~ AllenNLP original replace_corefs ~~~\n\"He is a great actor!\", he said about He.\n\n~~~ Our improved replace_corefs ~~~\n\"John Travolta is a great actor!\", he said about John Travolta.\n"
     ]
    }
   ],
   "source": [
    "print_comparison(original_replace_corefs(doc, clusters), improved_replace_corefs(doc, clusters))"
   ]
  },
  {
   "source": [
    "### Nested coreferent mentions\n",
    "I the case of nested mentions we choose to resolve the inner span (e.g. for the mention \"his dog\" the token *his* can be the inner span). That just means we don't want to resolve outer spans."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_containing_other_spans(span: List[int], all_spans: List[List[int]]):\n",
    "    return any([s[0] >= span[0] and s[1] <= span[1] and s != span for s in all_spans])\n",
    "\n",
    "\n",
    "def improved_replace_corefs(document, clusters):\n",
    "    resolved = list(tok.text_with_ws for tok in document)\n",
    "    all_spans = [span for cluster in clusters for span in cluster]  # flattened list of all spans\n",
    "\n",
    "    for cluster in clusters:\n",
    "        noun_indices = get_span_noun_indices(document, cluster)\n",
    "\n",
    "        if noun_indices:\n",
    "            mention_span, mention = get_cluster_head(document, cluster, noun_indices)\n",
    "\n",
    "            for coref in cluster:\n",
    "                if coref != mention and not is_containing_other_spans(coref, all_spans):\n",
    "                    core_logic_part(document, coref, resolved, mention_span)\n",
    "\n",
    "    return \"\".join(resolved)"
   ]
  },
  {
   "source": [
    "**Example**  \n",
    "Anna likes Tom. Tom is Anna's brother. Her brother is tall.\n",
    "\n",
    "**Original coreference resolution clusters** (by AllenNLP)  \n",
    "Tom --> Tom; Tom; Her brother  \n",
    "Anna --> Anna; Anna 's; Her"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Anna likes Tom. Tom is Anna's brother. Her brother is tall.\"\n",
    "clusters = predictor.predict(text)['clusters']\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "~~~ AllenNLP original replace_corefs ~~~\nAnna likes Tom. Tom is Anna's brother. Anna's is tall.\n\n~~~ Our improved replace_corefs ~~~\nAnna likes Tom. Tom is Anna's brother. Anna's brother is tall.\n"
     ]
    }
   ],
   "source": [
    "print_comparison(original_replace_corefs(doc, clusters), improved_replace_corefs(doc, clusters))"
   ]
  },
  {
   "source": [
    "Our last version of the `improved_replace_corefs` contains all of ours refinements. And that's it! You can now use it in your project with or without the intersection strategies (see the other Jupyter Notebook file). Good luck :sunglasses:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}